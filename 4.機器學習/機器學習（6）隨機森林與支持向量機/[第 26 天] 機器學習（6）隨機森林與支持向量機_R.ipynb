{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ithelp.ithome.com.tw/articles/10187569\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言\n",
    "\n",
    "## 隨機森林分類器\n",
    "屬於建構於決策樹之上的整體學習應用，\n",
    "\n",
    "每一個基本分類器都是一個決策樹。這時我們心中就冒出一個疑問：\n",
    "\n",
    "隨機森林跟以決策樹為基本分類器構成的 Bagging 有什麼不同？\n",
    "\n",
    ">最大的差異應該就是隨機的部分，以決策樹為基本分類器構成的 Bagging 的 Boostrap sampling 只有應用在列方向（觀測值方向）；\n",
    ">隨機森林的 bootstrap sampling 則是同時應用在列方向（觀測值方向）與欄方向（變數方向）。\n",
    "\n",
    "## 支持向量機\n",
    "則是一種利用最適化（Optimization）概念在模型的精確度以及推廣能力（Generalization ability）中取得一個最佳平衡點的演算法，\n",
    "她在面對小樣本，非線性與多維度的資料中廣受歡迎。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機森林\n",
    "\n",
    "隨機森林演算法會對資料從列方向（觀測值方向）與欄方向（變數方向）進行 Bootstrap sampling，\n",
    "\n",
    "得到不同的訓練資料，然後根據這些訓練資料得到一系列的決策樹分類器，假如產生了 5 個決策樹分類器，\n",
    "\n",
    "她們對某個觀測值的預測結果分別為 1, 0, 1, 1, 1，那麼隨機森林演算法的輸出結果就會是 1，\n",
    "\n",
    "這個過程與 Bagging 演算法相同，同樣稱為基本分類器的投票。\n",
    "\n",
    "隨機森林演算法在面對變數具有多元共線性或者不平衡資料（Unbalanced data）的情況時是倍受青睞的演算法。\n",
    "\n",
    "我們使用 randomForest 套件的 randomForest() 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.782771535580524"
      ],
      "text/latex": [
       "0.782771535580524"
      ],
      "text/markdown": [
       "0.782771535580524"
      ],
      "text/plain": [
       "[1] 0.7827715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(randomForest)\n",
    "\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train <- read.csv(url)\n",
    "titanic_train$Survived <- factor(titanic_train$Survived)\n",
    "\n",
    "# 將 Age 遺漏值以 median 填補\n",
    "age_median <- median(titanic_train$Age, na.rm = TRUE)\n",
    "new_Age <- ifelse(is.na(titanic_train$Age), age_median, titanic_train$Age)\n",
    "titanic_train$Age <- new_Age\n",
    "\n",
    "# 切分訓練與測試資料\n",
    "n <- nrow(titanic_train)\n",
    "shuffled_titanic <- titanic_train[sample(n), ]\n",
    "train_indices <- 1:round(0.7 * n)\n",
    "train_titanic <- shuffled_titanic[train_indices, ]\n",
    "test_indices <- (round(0.7 * n) + 1):n\n",
    "test_titanic <- shuffled_titanic[test_indices, ]\n",
    "\n",
    "# 建立模型\n",
    "forest_fit <- randomForest(Survived ~ Pclass + Age + Sex, data = train_titanic, n_tree = 100)\n",
    "\n",
    "# 預測\n",
    "test_titanic_predicted <- predict(forest_fit, test_titanic)\n",
    "\n",
    "# 績效\n",
    "conf_matrix <- table(test_titanic_predicted, test_titanic$Survived)\n",
    "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量機\n",
    "\n",
    "支持向量機是一種最小化結構風險（Structural risk）的演算法，\n",
    "\n",
    "何謂結構型風險？機器學習的內涵在於假設一個類似模型去逼近真實模型，\n",
    "\n",
    "而量化類似模型與真實模型之間差距的方式，跟我們在計算績效（準確率）用的概念是相同的，\n",
    "\n",
    "我們用類似模型預測的結果去跟答案比較。\n",
    "\n",
    "許多的分類器可以在訓練資料上達到很高的正確率（稱作 Overfitting），\n",
    "\n",
    "但是卻失去應用在實際問題的推廣能力（Generalization ability）。\n",
    "\n",
    "資料科學家將分類器在訓練樣本可能過度配適的風險稱為 Empirical risk，\n",
    "\n",
    "分類器的推廣能力不足的風險稱為 Generalization risk，兩者的總和即為結構風險，\n",
    "\n",
    "而支持向量機就是在兩者之間取得最佳平衡點，進而得到一個在訓練資料績效不錯，亦能推廣適用的類似模型。\n",
    "\n",
    "我們使用 e1071 套件的 svm() 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.790262172284644"
      ],
      "text/latex": [
       "0.790262172284644"
      ],
      "text/markdown": [
       "0.790262172284644"
      ],
      "text/plain": [
       "[1] 0.7902622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(e1071)\n",
    "\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train <- read.csv(url)\n",
    "titanic_train$Survived <- factor(titanic_train$Survived)\n",
    "\n",
    "# 將 Age 遺漏值以 median 填補\n",
    "age_median <- median(titanic_train$Age, na.rm = TRUE)\n",
    "new_Age <- ifelse(is.na(titanic_train$Age), age_median, titanic_train$Age)\n",
    "titanic_train$Age <- new_Age\n",
    "\n",
    "# 切分訓練與測試資料\n",
    "n <- nrow(titanic_train)\n",
    "shuffled_titanic <- titanic_train[sample(n), ]\n",
    "train_indices <- 1:round(0.7 * n)\n",
    "train_titanic <- shuffled_titanic[train_indices, ]\n",
    "test_indices <- (round(0.7 * n) + 1):n\n",
    "test_titanic <- shuffled_titanic[test_indices, ]\n",
    "\n",
    "# 建立模型\n",
    "svm_fit <- svm(Survived ~ Pclass + Age + Sex, data = train_titanic)\n",
    "\n",
    "# 預測\n",
    "test_titanic_predicted <- predict(svm_fit, test_titanic)\n",
    "\n",
    "# 績效\n",
    "conf_matrix <- table(test_titanic_predicted, test_titanic$Survived)\n",
    "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "在二元分類模型裡面，除了我們一直使用的準確率（Accuracy）以外，\n",
    "\n",
    "其實還有許多由 Confusion matrix 所衍生的績效指標，像是精確度（Precision）或者召回率（Recall）等，\n",
    "\n",
    "其中 AUC 是一個常見指標，它同時考慮假警報率（False alarm rate）與命中率（True positive rate），\n",
    "\n",
    "AUC 愈接近 1，就表示分類效果愈好；愈接近 0.5 就表示分類效果愈差不好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 效果\tAUC 區間\n",
    "\n",
    "傑出\tAUC 介於 0.9-1.0 之間\n",
    "\n",
    "優秀\tAUC 介於 0.8-0.9 之間\n",
    "\n",
    "普通\tAUC 介於 0.7-0.8 之間\n",
    "\n",
    "不好\tAUC 介於 0.6-0.7 之間\n",
    "\n",
    "差勁\tAUC 介於 0.5-0.6 之間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機森林分類器的 AUC\n",
    "\n",
    "在 R 語言使用 ROCR 套件的 performance() 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(ROCR): there is no package called 'ROCR'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(ROCR): there is no package called 'ROCR'\nTraceback:\n",
      "1. library(ROCR)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(randomForest)\n",
    "library(ROCR)\n",
    "\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train <- read.csv(url)\n",
    "titanic_train$Survived <- factor(titanic_train$Survived)\n",
    "\n",
    "# 將 Age 遺漏值以 median 填補\n",
    "age_median <- median(titanic_train$Age, na.rm = TRUE)\n",
    "new_Age <- ifelse(is.na(titanic_train$Age), age_median, titanic_train$Age)\n",
    "titanic_train$Age <- new_Age\n",
    "\n",
    "# 切分訓練與測試資料\n",
    "n <- nrow(titanic_train)\n",
    "shuffled_titanic <- titanic_train[sample(n), ]\n",
    "train_indices <- 1:round(0.7 * n)\n",
    "train_titanic <- shuffled_titanic[train_indices, ]\n",
    "test_indices <- (round(0.7 * n) + 1):n\n",
    "test_titanic <- shuffled_titanic[test_indices, ]\n",
    "\n",
    "# 建立模型\n",
    "forest_fit <- randomForest(Survived ~ Pclass + Age + Sex, data = train_titanic)\n",
    "\n",
    "# 預測\n",
    "test_titanic_predicted_prob <- predict(forest_fit, test_titanic, type = \"prob\")\n",
    "pred <- prediction(test_titanic_predicted_prob[, \"1\"], labels = test_titanic$Survived)\n",
    "\n",
    "# 績效\n",
    "perf <- performance(pred, \"auc\")\n",
    "auc <- perf@y.values[[1]]\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量機分類器的 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(e1071): there is no package called 'e1071'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(e1071): there is no package called 'e1071'\nTraceback:\n",
      "1. library(e1071)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(e1071)\n",
    "library(ROCR)\n",
    "\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train <- read.csv(url)\n",
    "titanic_train$Survived <- factor(titanic_train$Survived)\n",
    "\n",
    "# 將 Age 遺漏值以 median 填補\n",
    "age_median <- median(titanic_train$Age, na.rm = TRUE)\n",
    "new_Age <- ifelse(is.na(titanic_train$Age), age_median, titanic_train$Age)\n",
    "titanic_train$Age <- new_Age\n",
    "\n",
    "# 切分訓練與測試資料\n",
    "n <- nrow(titanic_train)\n",
    "shuffled_titanic <- titanic_train[sample(n), ]\n",
    "train_indices <- 1:round(0.7 * n)\n",
    "train_titanic <- shuffled_titanic[train_indices, ]\n",
    "test_indices <- (round(0.7 * n) + 1):n\n",
    "test_titanic <- shuffled_titanic[test_indices, ]\n",
    "\n",
    "# 建立模型\n",
    "svm_fit <- svm(Survived ~ Pclass + Age + Sex, data = train_titanic, probability = TRUE)\n",
    "\n",
    "# 預測\n",
    "test_titanic_predicted_prob <- predict(svm_fit, test_titanic, probability = TRUE)\n",
    "pred <- prediction(attr(test_titanic_predicted_prob, \"probabilities\")[, \"1\"], labels = test_titanic$Survived)\n",
    "\n",
    "# 績效\n",
    "perf <- performance(pred, \"auc\")\n",
    "auc <- perf@y.values[[1]]\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
